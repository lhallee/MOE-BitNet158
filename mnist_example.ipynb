{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "from config import BitformerConfig\n",
    "from model_zoo import VisionBitformerForImageClassification\n",
    "from trainer import get_trainer\n",
    "from data_zoo import get_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = './yamls/mnist.yaml'\n",
    "with open(yaml_path, 'r') as file:\n",
    "    args = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'general_config': {'model_type': 'VisionBitformerForImageClassification',\n",
       "  'num_labels': 10},\n",
       " 'model_config': {'vocab_size': 32000,\n",
       "  'hidden_size': 28,\n",
       "  'intermediate_size': 512,\n",
       "  'num_hidden_layers': 1,\n",
       "  'num_attention_heads': 2,\n",
       "  'num_key_value_heads': 2,\n",
       "  'hidden_act': 'silu',\n",
       "  'max_position_embeddings': 4096,\n",
       "  'initializer_range': 0.02,\n",
       "  'rms_norm_eps': 1e-05,\n",
       "  'use_cache': False,\n",
       "  'pad_token_id': None,\n",
       "  'bos_token_id': 1,\n",
       "  'eos_token_id': 2,\n",
       "  'tie_word_embeddings': False,\n",
       "  'rope_theta': 1000000.0,\n",
       "  'sliding_window': 4096,\n",
       "  'attention_dropout': 0.0,\n",
       "  'num_experts_per_tok': 2,\n",
       "  'num_local_experts': 4,\n",
       "  'output_router_logits': True,\n",
       "  'router_aux_loss_coef': 0.001,\n",
       "  'is_causal': False,\n",
       "  'moe': True,\n",
       "  'bitnet': False},\n",
       " 'training_args': {'output_dir': './results',\n",
       "  'logging_dir': './logs',\n",
       "  'report_to': None,\n",
       "  'evaluation_strategy': 'epoch',\n",
       "  'per_device_train_batch_size': 64,\n",
       "  'per_device_eval_batch_size': 64,\n",
       "  'gradient_accumulation_steps': 1,\n",
       "  'learning_rate': 0.0005,\n",
       "  'weight_decay': 0.01,\n",
       "  'num_train_epochs': 10,\n",
       "  'warmup_ratio': 0.0,\n",
       "  'warmup_steps': 100,\n",
       "  'lr_scheduler_type': 'cosine',\n",
       "  'save_strategy': 'epoch',\n",
       "  'save_steps': 500,\n",
       "  'save_total_limit': 2,\n",
       "  'dataloader_drop_last': False,\n",
       "  'eval_steps': None,\n",
       "  'dataloader_num_workers': 0,\n",
       "  'logging_strategy': 'steps',\n",
       "  'logging_first_step': False,\n",
       "  'logging_steps': 500,\n",
       "  'bf16': False,\n",
       "  'fp16': False,\n",
       "  'seed': 42,\n",
       "  'adam_beta1': 0.9,\n",
       "  'adam_beta2': 0.999,\n",
       "  'adam_epsilon': 1e-08,\n",
       "  'max_grad_norm': 1.0,\n",
       "  'do_train': True,\n",
       "  'do_eval': True,\n",
       "  'do_predict': False,\n",
       "  'eval_accumulation_steps': None,\n",
       "  'group_by_length': False,\n",
       "  'length_column_name': 'length',\n",
       "  'save_safetensors': True,\n",
       "  'optim': 'adamw_torch',\n",
       "  'eval_delay': 0,\n",
       "  'max_steps': -1,\n",
       "  'overwrite_output_dir': False,\n",
       "  'prediction_loss_only': False,\n",
       "  'lr_scheduler_kwargs': None,\n",
       "  'log_level': 'passive',\n",
       "  'log_level_replica': 'warning',\n",
       "  'log_on_each_node': True,\n",
       "  'logging_nan_inf_filter': True,\n",
       "  'fp16_opt_level': 'O1',\n",
       "  'half_precision_backend': 'auto',\n",
       "  'bf16_full_eval': False,\n",
       "  'fp16_full_eval': False,\n",
       "  'per_gpu_train_batch_size': None,\n",
       "  'per_gpu_eval_batch_size': None,\n",
       "  'tf32': None,\n",
       "  'local_rank': -1,\n",
       "  'ddp_backend': None,\n",
       "  'tpu_num_cores': None,\n",
       "  'tpu_metrics_debug': False,\n",
       "  'debug': '',\n",
       "  'save_on_each_node': False,\n",
       "  'save_only_model': False,\n",
       "  'no_cuda': False,\n",
       "  'use_cpu': False,\n",
       "  'use_mps_device': False,\n",
       "  'data_seed': None,\n",
       "  'jit_mode_eval': False,\n",
       "  'use_ipex': False,\n",
       "  'dataloader_prefetch_factor': None,\n",
       "  'past_index': -1,\n",
       "  'run_name': None,\n",
       "  'disable_tqdm': None,\n",
       "  'remove_unused_columns': True,\n",
       "  'label_names': None,\n",
       "  'load_best_model_at_end': True,\n",
       "  'metric_for_best_model': 'accuracy',\n",
       "  'greater_is_better': True,\n",
       "  'ignore_data_skip': False,\n",
       "  'fsdp': '',\n",
       "  'fsdp_min_num_params': 0,\n",
       "  'fsdp_config': None,\n",
       "  'fsdp_transformer_layer_cls_to_wrap': None,\n",
       "  'accelerator_config': None,\n",
       "  'deepspeed': None,\n",
       "  'label_smoothing_factor': 0.0,\n",
       "  'optim_args': None,\n",
       "  'adafactor': False,\n",
       "  'ddp_find_unused_parameters': None,\n",
       "  'ddp_bucket_cap_mb': None,\n",
       "  'ddp_broadcast_buffers': None,\n",
       "  'dataloader_pin_memory': True,\n",
       "  'dataloader_persistent_workers': False,\n",
       "  'skip_memory_metrics': True,\n",
       "  'use_legacy_prediction_loop': False,\n",
       "  'push_to_hub': False,\n",
       "  'resume_from_checkpoint': None,\n",
       "  'hub_model_id': None,\n",
       "  'hub_strategy': 'every_save',\n",
       "  'hub_token': None,\n",
       "  'hub_private_repo': False,\n",
       "  'hub_always_push': False,\n",
       "  'gradient_checkpointing': False,\n",
       "  'gradient_checkpointing_kwargs': None,\n",
       "  'include_inputs_for_metrics': False,\n",
       "  'fp16_backend': 'auto',\n",
       "  'push_to_hub_model_id': None,\n",
       "  'push_to_hub_organization': None,\n",
       "  'push_to_hub_token': None,\n",
       "  'mp_parameters': '',\n",
       "  'auto_find_batch_size': False,\n",
       "  'full_determinism': False,\n",
       "  'torchdynamo': None,\n",
       "  'ray_scope': 'last',\n",
       "  'ddp_timeout': 1800,\n",
       "  'torch_compile': False,\n",
       "  'torch_compile_backend': None,\n",
       "  'torch_compile_mode': None,\n",
       "  'dispatch_batches': None,\n",
       "  'split_batches': None,\n",
       "  'include_tokens_per_second': None,\n",
       "  'include_num_input_tokens_seen': None,\n",
       "  'neftune_noise_alpha': None}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.071644"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = BitformerConfig(**args['model_config'], num_labels=args['general_config']['num_labels'])\n",
    "model = VisionBitformerForImageClassification(config=cfg)\n",
    "model.num_parameters() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "def data_collator(batch):\n",
    "    pixel_values = torch.stack([item[0].squeeze(0).reshape(28, 28) for item in batch])\n",
    "    labels = torch.tensor([item[1] for item in batch])\n",
    "    return {'inputs_embeds': pixel_values, 'labels': labels}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./mnist_data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./mnist_data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = get_trainer(model, train_dataset, test_dataset, data_collator, **args['training_args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a9d5eb78404facb07c8b4140da4664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8517, 'grad_norm': 2.1099369525909424, 'learning_rate': 0.0004977113991447017, 'epoch': 0.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1738e6b24a4d4ace859eb677e0649af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 765    0    7    0    6   25   37    1  134    5]\n",
      " [   0 1115    5    2    0    4    6    0    3    0]\n",
      " [  20    0  675  174   27   54   64    4   14    0]\n",
      " [   4   17   97  745   10   42    4   51   17   23]\n",
      " [  41    0   13   16  673    7   22   13   28  169]\n",
      " [  41   10   87  173   25  360   29   20  135   12]\n",
      " [  51   14   31    0    6   13  832    0   11    0]\n",
      " [   0   14   14   53   10    1    0  838    3   95]\n",
      " [  68   17    4   21   22   27   22    2  766   25]\n",
      " [  12    8    1   19   73    5    0  134   22  735]]\n",
      "{'eval_loss': 0.7526538968086243, 'eval_f1': 0.7456515832870662, 'eval_precision': 0.7501509712491882, 'eval_recall': 0.7504, 'eval_accuracy': 0.7504, 'eval_runtime': 2.1495, 'eval_samples_per_second': 4652.276, 'eval_steps_per_second': 73.041, 'epoch': 1.0}\n",
      "{'loss': 0.9053, 'grad_norm': 1.7508418560028076, 'learning_rate': 0.0004884857252366847, 'epoch': 1.07}\n",
      "{'loss': 0.6585, 'grad_norm': 2.313500165939331, 'learning_rate': 0.00047244343235328215, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03e599b758a45b793b087340b773a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 825    0    3    0    0   31   27    3   89    2]\n",
      " [   0 1112    9    1    0    3    4    0    6    0]\n",
      " [   6    7  827  101    3   55   20    4    8    1]\n",
      " [   0   14   58  871    2   18    0   31    9    7]\n",
      " [   9    4   17    8  773    5    5   21   10  130]\n",
      " [  10    7   42  142    8  623   13    3   36    8]\n",
      " [  28   12   34    0    7   20  846    1   10    0]\n",
      " [   0   13   15   14    8    2    0  919    2   55]\n",
      " [  42   12    4   21   13   67   18    4  785    8]\n",
      " [   5    5    0   18   44   21    0   68    8  840]]\n",
      "{'eval_loss': 0.4991087317466736, 'eval_f1': 0.8419552749689246, 'eval_precision': 0.8439905647740618, 'eval_recall': 0.8421, 'eval_accuracy': 0.8421, 'eval_runtime': 2.1488, 'eval_samples_per_second': 4653.858, 'eval_steps_per_second': 73.066, 'epoch': 2.0}\n",
      "{'loss': 0.5284, 'grad_norm': 3.591857433319092, 'learning_rate': 0.00045004305610692587, 'epoch': 2.13}\n",
      "{'loss': 0.4514, 'grad_norm': 3.017133951187134, 'learning_rate': 0.00042192486471335583, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0bd3aef5364742b98117bf6417fa07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 902    0    1    1    1    5   32    2   34    2]\n",
      " [   0 1105    6    2    0    5   13    0    4    0]\n",
      " [  10    2  876   39    5   47   40    3    9    1]\n",
      " [   0    7   69  854    0   34    0   22   10   14]\n",
      " [   8    3   12    1  872    2    9    6    5   64]\n",
      " [   8    3   21   73    6  733   10    4   28    6]\n",
      " [  23    5    7    0    6   10  902    0    5    0]\n",
      " [   0   17   20   12   11    5    0  881    2   80]\n",
      " [  80   13    5   17   15   39   38    3  756    8]\n",
      " [   9    7    0   15   73   15    0   32   11  847]]\n",
      "{'eval_loss': 0.3913519084453583, 'eval_f1': 0.8723047395892015, 'eval_precision': 0.8731715651243441, 'eval_recall': 0.8728, 'eval_accuracy': 0.8728, 'eval_runtime': 2.198, 'eval_samples_per_second': 4549.644, 'eval_steps_per_second': 71.429, 'epoch': 3.0}\n",
      "{'loss': 0.4087, 'grad_norm': 3.228550434112549, 'learning_rate': 0.00038889255825490053, 'epoch': 3.2}\n",
      "{'loss': 0.3771, 'grad_norm': 3.2687485218048096, 'learning_rate': 0.00035189029658340025, 'epoch': 3.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2804ce400b2449bb79bff5d0e6b4121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 884    0    3    0    2    4   31    1   48    7]\n",
      " [   0 1105   10    4    0    3    7    0    6    0]\n",
      " [   6    2  863   97    6   17   22    6   10    3]\n",
      " [   0    7   27  933    0    9    0   19    5   10]\n",
      " [   2    3    4    1  884    0    4    9    5   70]\n",
      " [   2    7   17  130   10  660   11    5   39   11]\n",
      " [   5    4   12    1   15    4  906    2    9    0]\n",
      " [   0    9   13   11    8    1    0  921    0   65]\n",
      " [  27   12    9   22   15   16   18    5  832   18]\n",
      " [   3    7    3   11   40    3    0   31   12  899]]\n",
      "{'eval_loss': 0.3567127287387848, 'eval_f1': 0.888568893545601, 'eval_precision': 0.892290807495399, 'eval_recall': 0.8887, 'eval_accuracy': 0.8887, 'eval_runtime': 2.391, 'eval_samples_per_second': 4182.27, 'eval_steps_per_second': 65.662, 'epoch': 4.0}\n",
      "{'loss': 0.3565, 'grad_norm': 1.8129571676254272, 'learning_rate': 0.00031197571247243834, 'epoch': 4.26}\n",
      "{'loss': 0.3294, 'grad_norm': 3.4569573402404785, 'learning_rate': 0.00027028968138185784, 'epoch': 4.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc24259e1904cfa9d52eb7882c579ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 942    0    1    0    1    4    9    0   19    4]\n",
      " [   0 1102    7    1    0    4    7    0   14    0]\n",
      " [  14    2  849   91    3   20   24   11   13    5]\n",
      " [   0    4   20  930    0   15    0   18   15    8]\n",
      " [   3    4    5    0  874    0    2    9    9   76]\n",
      " [   3    3    8   69    3  751    5    5   36    9]\n",
      " [  14    4   14    1   13   11  889    1   10    1]\n",
      " [   0   11   15   11   11    1    0  935    1   43]\n",
      " [  31    8    7   22    9   19   10    3  857    8]\n",
      " [   7    8    1   10   35    5    0   36   17  890]]\n",
      "{'eval_loss': 0.3156144917011261, 'eval_f1': 0.9018494491308952, 'eval_precision': 0.903299262243816, 'eval_recall': 0.9019, 'eval_accuracy': 0.9019, 'eval_runtime': 2.1664, 'eval_samples_per_second': 4615.988, 'eval_steps_per_second': 72.471, 'epoch': 5.0}\n",
      "{'loss': 0.318, 'grad_norm': 3.1098461151123047, 'learning_rate': 0.00022802371190303695, 'epoch': 5.33}\n",
      "{'loss': 0.3066, 'grad_norm': 2.346620559692383, 'learning_rate': 0.00018638588896129557, 'epoch': 5.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0677e4dbb54093b3031212d4fe5ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 922    0    2    1    0    4   37    0   11    3]\n",
      " [   0 1110    6    1    0    4    6    0    8    0]\n",
      " [   7    2  899   48    3   25   33    5   10    0]\n",
      " [   1    9   56  879    0   34    0   14   15    2]\n",
      " [   2    4    6    0  905    4   10    8    8   35]\n",
      " [   2    6   14   40    2  790   11    2   21    4]\n",
      " [   7    4    7    1    2    4  927    2    4    0]\n",
      " [   0   20   19   12   15    4    0  915    4   39]\n",
      " [  32   12    8   19    6   32   29    2  830    4]\n",
      " [   7   10    6   15   57   10    0   36   24  844]]\n",
      "{'eval_loss': 0.304097056388855, 'eval_f1': 0.9017282130790071, 'eval_precision': 0.9022932979024486, 'eval_recall': 0.9021, 'eval_accuracy': 0.9021, 'eval_runtime': 2.1704, 'eval_samples_per_second': 4607.478, 'eval_steps_per_second': 72.337, 'epoch': 6.0}\n",
      "{'loss': 0.291, 'grad_norm': 1.29850435256958, 'learning_rate': 0.0001465663432182349, 'epoch': 6.4}\n",
      "{'loss': 0.2861, 'grad_norm': 2.469521999359131, 'learning_rate': 0.00010970323365940444, 'epoch': 6.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1c91bb8f9e42d580b65fe279ebc7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 953    0    3    1    0    3    7    0   10    3]\n",
      " [   0 1105    6    1    0    4    6    0   12    1]\n",
      " [   6    5  904   58    3   15   20    6   12    3]\n",
      " [   0    5   42  924    0   15    0   11    9    4]\n",
      " [   2    3    4    1  894    1    3   11    8   55]\n",
      " [   2    4   15   43    3  784    6    2   26    7]\n",
      " [  13    4   11    1    9    9  900    2    9    0]\n",
      " [   0   17   15   15   12    2    0  922    1   44]\n",
      " [  26   10    9   22    7   21    7    3  863    6]\n",
      " [   6   11    6   19   29    5    0   27   14  892]]\n",
      "{'eval_loss': 0.2785503566265106, 'eval_f1': 0.9140589032462638, 'eval_precision': 0.9145182921052126, 'eval_recall': 0.9141, 'eval_accuracy': 0.9141, 'eval_runtime': 2.2112, 'eval_samples_per_second': 4522.393, 'eval_steps_per_second': 71.002, 'epoch': 7.0}\n",
      "{'loss': 0.2864, 'grad_norm': 1.9672399759292603, 'learning_rate': 7.685021568435078e-05, 'epoch': 7.46}\n",
      "{'loss': 0.2665, 'grad_norm': 2.6236050128936768, 'learning_rate': 4.894632455610773e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cff88c9d8a248b6b75afca4dd0ffc90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 942    0    2    1    0    6   15    0   11    3]\n",
      " [   0 1107    7    1    0    4    6    0    9    1]\n",
      " [   6    3  894   64    5   18   20    8   11    3]\n",
      " [   0    3   35  929    0   16    0   13   10    4]\n",
      " [   0    2    4    1  893    2    3   10    9   58]\n",
      " [   2    5    7   49    3  787    5    3   24    7]\n",
      " [   6    4   10    1    9    9  908    2    9    0]\n",
      " [   0   14   16   12   11    4    0  927    1   43]\n",
      " [  20    8    9   23    6   25    7    3  866    7]\n",
      " [   4    9    6   12   30    5    0   32   15  896]]\n",
      "{'eval_loss': 0.269232839345932, 'eval_f1': 0.9149048708630928, 'eval_precision': 0.9153808479189037, 'eval_recall': 0.9149, 'eval_accuracy': 0.9149, 'eval_runtime': 2.2408, 'eval_samples_per_second': 4462.758, 'eval_steps_per_second': 70.065, 'epoch': 8.0}\n",
      "{'loss': 0.2616, 'grad_norm': 2.2810122966766357, 'learning_rate': 2.6789135029152173e-05, 'epoch': 8.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f10044fc6c47d7ac57f3d93fec3f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 942    0    2    1    0    6   16    0   10    3]\n",
      " [   0 1106    6    2    0    4    6    0   10    1]\n",
      " [   6    3  901   61    5   16   19    8   10    3]\n",
      " [   0    3   39  930    0   16    0   12    6    4]\n",
      " [   0    2    4    1  907    1    3   10    6   48]\n",
      " [   2    4   10   47    3  788    5    3   23    7]\n",
      " [   7    3   10    1   10    9  910    1    7    0]\n",
      " [   0   14   17   12   13    3    0  928    1   40]\n",
      " [  22    8    9   23    7   26   10    3  859    7]\n",
      " [   4    9    6   16   35    5    0   31   14  889]]\n",
      "{'eval_loss': 0.2673957645893097, 'eval_f1': 0.9159655975632608, 'eval_precision': 0.9163724161435439, 'eval_recall': 0.916, 'eval_accuracy': 0.916, 'eval_runtime': 2.0843, 'eval_samples_per_second': 4797.723, 'eval_steps_per_second': 75.324, 'epoch': 9.0}\n",
      "{'loss': 0.2748, 'grad_norm': 2.7655932903289795, 'learning_rate': 1.1011964332097113e-05, 'epoch': 9.06}\n",
      "{'loss': 0.264, 'grad_norm': 2.1739659309387207, 'learning_rate': 2.065770110498438e-06, 'epoch': 9.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0827fafd344f66b3c1a92d77fa37cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-9380 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 945    0    2    1    0    5   15    0    9    3]\n",
      " [   0 1105    6    2    0    4    6    0   11    1]\n",
      " [   6    3  896   61    5   17   22    9   10    3]\n",
      " [   0    3   40  925    0   16    0   12   10    4]\n",
      " [   0    2    4    1  907    1    3    9    6   49]\n",
      " [   2    4   11   47    3  786    5    3   24    7]\n",
      " [   7    3   10    1   10    9  910    1    7    0]\n",
      " [   0   14   17   13   13    3    0  925    1   42]\n",
      " [  24    9    9   22    7   22   10    3  861    7]\n",
      " [   5    8    6   12   36    5    0   30   15  892]]\n",
      "{'eval_loss': 0.2666623294353485, 'eval_f1': 0.9151400967608606, 'eval_precision': 0.9154825760974205, 'eval_recall': 0.9152, 'eval_accuracy': 0.9152, 'eval_runtime': 2.1742, 'eval_samples_per_second': 4599.459, 'eval_steps_per_second': 72.212, 'epoch': 10.0}\n",
      "{'train_runtime': 194.9569, 'train_samples_per_second': 3077.603, 'train_steps_per_second': 48.113, 'train_loss': 0.45974236998730883, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc9443cc62b45558c5ea704c335142f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 942    0    2    1    0    6   16    0   10    3]\n",
      " [   0 1106    6    2    0    4    6    0   10    1]\n",
      " [   6    3  901   61    5   16   19    8   10    3]\n",
      " [   0    3   39  930    0   16    0   12    6    4]\n",
      " [   0    2    4    1  907    1    3   10    6   48]\n",
      " [   2    4   10   47    3  788    5    3   23    7]\n",
      " [   7    3   10    1   10    9  910    1    7    0]\n",
      " [   0   14   17   12   13    3    0  928    1   40]\n",
      " [  22    8    9   23    7   26   10    3  859    7]\n",
      " [   4    9    6   16   35    5    0   31   14  889]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2673957645893097,\n",
       " 'eval_f1': 0.9159655975632608,\n",
       " 'eval_precision': 0.9163724161435439,\n",
       " 'eval_recall': 0.916,\n",
       " 'eval_accuracy': 0.916,\n",
       " 'eval_runtime': 2.2432,\n",
       " 'eval_samples_per_second': 4457.904,\n",
       " 'eval_steps_per_second': 69.989,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cb21e8f88f84fe8ad9bd168ff2e2eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5768, 'grad_norm': 6.464507102966309, 'learning_rate': 0.0004977113991447017, 'epoch': 0.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57961c3697084317a41c4444dedc8abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 877    0    6    1   24    7   22    1   41    1]\n",
      " [   0 1027   16   13    3   46    6    7   15    2]\n",
      " [  50    5  648   57   40   87   65    3   69    8]\n",
      " [   2    4  105  701   11   52    2   18   48   67]\n",
      " [  43    4   18    2  659    9    4    8  163   72]\n",
      " [  33   11   44   54   37  581   14    6   87   25]\n",
      " [  18    2   15    2    3    5  846    0   67    0]\n",
      " [   0   12    2   12   45   20    0  696    5  236]\n",
      " [  55    1   12   10   21   22   10    3  823   17]\n",
      " [   8    4    1    9  170    3    1   15   48  750]]\n",
      "{'eval_loss': 0.7616570591926575, 'eval_f1': 0.7619962587705958, 'eval_precision': 0.7746075940242815, 'eval_recall': 0.7608, 'eval_accuracy': 0.7608, 'eval_runtime': 3.6155, 'eval_samples_per_second': 2765.841, 'eval_steps_per_second': 43.424, 'epoch': 1.0}\n",
      "{'loss': 0.8529, 'grad_norm': 10.953009605407715, 'learning_rate': 0.0004884857252366847, 'epoch': 1.07}\n",
      "{'loss': 0.6767, 'grad_norm': 20.91096305847168, 'learning_rate': 0.00047244343235328215, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0221d3bed4804d7a9e003f86b7e20080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 805    0   11    2   28   34   29    5   59    7]\n",
      " [   0 1079    4    4    3   11    4   16   14    0]\n",
      " [  18   19  750  106   10   76   17   13   18    5]\n",
      " [   0    7   29  821    2   52    3   49   17   30]\n",
      " [  17    6    9    5  688   50    8   27   57  115]\n",
      " [   2   11   21   63   10  734   15   12   19    5]\n",
      " [   5    8   18    0   12   26  880    0    9    0]\n",
      " [   0   10    5   21   13   19    0  879    1   80]\n",
      " [  23    3    9   16   16   78   23    1  771   34]\n",
      " [   1    1    0   27   29   26    1   98   16  810]]\n",
      "{'eval_loss': 0.5544259548187256, 'eval_f1': 0.8223033609959465, 'eval_precision': 0.8283879974033689, 'eval_recall': 0.8217, 'eval_accuracy': 0.8217, 'eval_runtime': 3.6611, 'eval_samples_per_second': 2731.41, 'eval_steps_per_second': 42.883, 'epoch': 2.0}\n",
      "{'loss': 0.5864, 'grad_norm': 8.617034912109375, 'learning_rate': 0.00045004305610692587, 'epoch': 2.13}\n",
      "{'loss': 0.492, 'grad_norm': 15.679028511047363, 'learning_rate': 0.00042192486471335583, 'epoch': 2.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cfb3b9c49545158bd97e275f8722ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 893    0   25    0    9    3   10    4   31    5]\n",
      " [   0 1108   13    2    1    2    3    2    3    1]\n",
      " [  11   11  948   18    4   26    7    4    2    1]\n",
      " [   0   10  146  780    2   32    1   25    6    8]\n",
      " [  22    3   30    8  722   20    8   24   57   88]\n",
      " [   8    3   64   33    3  748    9    3   15    6]\n",
      " [   4    2   15    2   10    6  909    0   10    0]\n",
      " [   0   14   36   15    9    8    0  857    3   86]\n",
      " [  34    5   11   21   17   24   20    1  807   34]\n",
      " [   5    1    5   21   23   17    0   62    8  867]]\n",
      "{'eval_loss': 0.4066694974899292, 'eval_f1': 0.863750619304394, 'eval_precision': 0.8684244303991644, 'eval_recall': 0.8639, 'eval_accuracy': 0.8639, 'eval_runtime': 3.6374, 'eval_samples_per_second': 2749.242, 'eval_steps_per_second': 43.163, 'epoch': 3.0}\n",
      "{'loss': 0.4436, 'grad_norm': 5.626135349273682, 'learning_rate': 0.00038889255825490053, 'epoch': 3.2}\n",
      "{'loss': 0.3974, 'grad_norm': 5.975671291351318, 'learning_rate': 0.00035189029658340025, 'epoch': 3.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33650822d5a4ff981158c77c328c364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 936    0    4    0   11    1    4    2   18    4]\n",
      " [   0 1120    5    2    1    0    5    0    2    0]\n",
      " [  16   14  922   54    3    4   13    3    3    0]\n",
      " [   1   31   32  893    3    2   12   30    3    3]\n",
      " [  18    5   12   11  853    7   21    8   13   34]\n",
      " [  15   15   79   79    7  641   29    4   14    9]\n",
      " [   8    3    8    1   14    1  915    0    8    0]\n",
      " [   0   11   16   39   19    0    0  863    4   76]\n",
      " [  45   15   10   27   21    8   34    5  796   13]\n",
      " [  10    8    2   14   77    7    1   29   13  848]]\n",
      "{'eval_loss': 0.3845398724079132, 'eval_f1': 0.8775848509542602, 'eval_precision': 0.8816738631728249, 'eval_recall': 0.8787, 'eval_accuracy': 0.8787, 'eval_runtime': 3.6513, 'eval_samples_per_second': 2738.768, 'eval_steps_per_second': 42.999, 'epoch': 4.0}\n",
      "{'loss': 0.3618, 'grad_norm': 5.224878787994385, 'learning_rate': 0.00031197571247243834, 'epoch': 4.26}\n",
      "{'loss': 0.325, 'grad_norm': 9.919211387634277, 'learning_rate': 0.00027028968138185784, 'epoch': 4.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fc500b3e27456392dc9f7385b4a0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 932    0    5    0   16    1   16    2    7    1]\n",
      " [   0 1114    5    2    0    0    3    0   11    0]\n",
      " [   8   11  954   23    5    4    8    8    7    4]\n",
      " [   0   18   37  897    0   18    3   17    9   11]\n",
      " [  10    8   12    1  829    5   20    5   37   55]\n",
      " [   7    4   55   51   11  695   32    3   17   17]\n",
      " [   5    2    8    1    7    2  926    1    6    0]\n",
      " [   0   11    9   11   17    2    0  902    5   71]\n",
      " [  22    4   11   17    3   14   37    0  858    8]\n",
      " [   4    5    2   14   43    5    1   22   28  885]]\n",
      "{'eval_loss': 0.3215293288230896, 'eval_f1': 0.8986272841009766, 'eval_precision': 0.9002846041239704, 'eval_recall': 0.8992, 'eval_accuracy': 0.8992, 'eval_runtime': 3.6957, 'eval_samples_per_second': 2705.867, 'eval_steps_per_second': 42.482, 'epoch': 5.0}\n",
      "{'loss': 0.3149, 'grad_norm': 14.113794326782227, 'learning_rate': 0.00022802371190303695, 'epoch': 5.33}\n",
      "{'loss': 0.301, 'grad_norm': 13.288413047790527, 'learning_rate': 0.00018638588896129557, 'epoch': 5.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19294c9f6641430bb97f09183c67a5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 957    0    1    0    2    4    7    1    7    1]\n",
      " [   0 1122    3    1    1    0    4    1    3    0]\n",
      " [  16   27  861   57    5   30    9   17    6    4]\n",
      " [   2   13   16  935    1   12    0   24    3    4]\n",
      " [  10    5    3    3  827   24   14    8   10   78]\n",
      " [   4    4    3   40    2  812    7    2   14    4]\n",
      " [   6    3    3    4    7    7  926    0    2    0]\n",
      " [   1    8   10   12   20    5    0  888    4   80]\n",
      " [  31    5    2   15    3   35   37    6  821   19]\n",
      " [  14    4    1    7   25   12    1   13   13  919]]\n",
      "{'eval_loss': 0.2990776300430298, 'eval_f1': 0.9063381509815707, 'eval_precision': 0.9087926569387182, 'eval_recall': 0.9068, 'eval_accuracy': 0.9068, 'eval_runtime': 3.5378, 'eval_samples_per_second': 2826.646, 'eval_steps_per_second': 44.378, 'epoch': 6.0}\n",
      "{'loss': 0.2858, 'grad_norm': 4.608861923217773, 'learning_rate': 0.0001465663432182349, 'epoch': 6.4}\n",
      "{'loss': 0.2742, 'grad_norm': 9.254112243652344, 'learning_rate': 0.00010970323365940444, 'epoch': 6.93}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d14c1995884ca4a7755fa1a14c8b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 925    0    7    1   13    4    1    1   23    5]\n",
      " [   0 1112    3    5    0    3    4    4    3    1]\n",
      " [  10    8  886   80   11   15    5   14    2    1]\n",
      " [   0    8   12  945    1   21    0   17    3    3]\n",
      " [   2    3    6    3  815    6    7   21    7  112]\n",
      " [   2    4   14   50    8  775    2    3   19   15]\n",
      " [   5    2    2    4   23   11  899    0   11    1]\n",
      " [   0    9    8   20    6    2    0  914    1   68]\n",
      " [  15    5    2   35    9   16    8    3  855   26]\n",
      " [   5    2    1   18    9    5    0   20    5  944]]\n",
      "{'eval_loss': 0.27679070830345154, 'eval_f1': 0.907416436375048, 'eval_precision': 0.9107548690543191, 'eval_recall': 0.907, 'eval_accuracy': 0.907, 'eval_runtime': 3.6525, 'eval_samples_per_second': 2737.86, 'eval_steps_per_second': 42.984, 'epoch': 7.0}\n",
      "{'loss': 0.2604, 'grad_norm': 19.479860305786133, 'learning_rate': 7.685021568435078e-05, 'epoch': 7.46}\n",
      "{'loss': 0.2514, 'grad_norm': 12.069538116455078, 'learning_rate': 4.894632455610773e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3ef8bb7edf415ebb34d58600ea16cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 943    0    6    0    5    5    4    1   13    3]\n",
      " [   0 1112    3    2    0    0    3    0   14    1]\n",
      " [  10   10  908   39    8   26    3   17   10    1]\n",
      " [   3    8   16  920    0   24    1   17   12    9]\n",
      " [   4    2    2    2  826   11    6   32   23   74]\n",
      " [   2    2    5   30    5  804    9    2   29    4]\n",
      " [   3    4    3    3   14   11  909    0   11    0]\n",
      " [   0    8    5   15    5    3    0  951    4   37]\n",
      " [  17    3    1    8    3   15    6    2  907   12]\n",
      " [   7    1    0   11   11   10    0   40   21  908]]\n",
      "{'eval_loss': 0.26105132699012756, 'eval_f1': 0.9188035293363653, 'eval_precision': 0.9200859889091951, 'eval_recall': 0.9188, 'eval_accuracy': 0.9188, 'eval_runtime': 3.6244, 'eval_samples_per_second': 2759.085, 'eval_steps_per_second': 43.318, 'epoch': 8.0}\n",
      "{'loss': 0.2416, 'grad_norm': 8.064125061035156, 'learning_rate': 2.6789135029152173e-05, 'epoch': 8.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a12371b3694070ad0bce6f64c718b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 925    0    4    0    9    4    8    2   21    7]\n",
      " [   0 1116    2    1    1    4    5    0    6    0]\n",
      " [   8   11  944   23    6   19    5   10    5    1]\n",
      " [   1    9   16  943    0   24    0   10    5    2]\n",
      " [   3    3    7    3  875   13   11    6   19   42]\n",
      " [   5    2    8   27    2  824    5    1   12    6]\n",
      " [   4    2    2    4   10    9  920    0    7    0]\n",
      " [   0   15   14   13   21    2    0  900    6   57]\n",
      " [  12    4    4   17    2   22    9    0  900    4]\n",
      " [   6    4    1   14   30   12    0   12   16  914]]\n",
      "{'eval_loss': 0.242593914270401, 'eval_f1': 0.9260794668701173, 'eval_precision': 0.9267383853604548, 'eval_recall': 0.9261, 'eval_accuracy': 0.9261, 'eval_runtime': 3.6315, 'eval_samples_per_second': 2753.698, 'eval_steps_per_second': 43.233, 'epoch': 9.0}\n",
      "{'loss': 0.2442, 'grad_norm': 4.718122959136963, 'learning_rate': 1.1011964332097113e-05, 'epoch': 9.06}\n",
      "{'loss': 0.2297, 'grad_norm': 4.965157985687256, 'learning_rate': 2.065770110498438e-06, 'epoch': 9.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0865991ccac34028b4ed355b22eb7df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 944    0    5    0    6    3    7    2   12    1]\n",
      " [   0 1119    3    2    0    1    4    0    6    0]\n",
      " [   8    9  968   20    2   11    4    8    2    0]\n",
      " [   2    8   21  949    0   12    1   10    4    3]\n",
      " [   2    5   11    2  897   10   12    7   10   26]\n",
      " [   3    3   15   35    2  808    8    1   12    5]\n",
      " [   5    2    6    2    8    6  922    0    7    0]\n",
      " [   0   15   16    9   18    2    0  919    5   44]\n",
      " [  23    3    5   22    6   18    9    0  882    6]\n",
      " [   8    3    4   15   57    9    0   22   14  877]]\n",
      "{'eval_loss': 0.23178459703922272, 'eval_f1': 0.9282962114422455, 'eval_precision': 0.9285663043775354, 'eval_recall': 0.9285, 'eval_accuracy': 0.9285, 'eval_runtime': 3.5961, 'eval_samples_per_second': 2780.803, 'eval_steps_per_second': 43.659, 'epoch': 10.0}\n",
      "{'train_runtime': 340.4996, 'train_samples_per_second': 1762.117, 'train_steps_per_second': 27.548, 'train_loss': 0.44155973503584545, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=9380, training_loss=0.44155973503584545, metrics={'train_runtime': 340.4996, 'train_samples_per_second': 1762.117, 'train_steps_per_second': 27.548, 'train_loss': 0.44155973503584545, 'epoch': 10.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c014f8059ab44dd8bee09948cded534d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 944    0    5    0    6    3    7    2   12    1]\n",
      " [   0 1119    3    2    0    1    4    0    6    0]\n",
      " [   8    9  968   20    2   11    4    8    2    0]\n",
      " [   2    8   21  949    0   12    1   10    4    3]\n",
      " [   2    5   11    2  897   10   12    7   10   26]\n",
      " [   3    3   15   35    2  808    8    1   12    5]\n",
      " [   5    2    6    2    8    6  922    0    7    0]\n",
      " [   0   15   16    9   18    2    0  919    5   44]\n",
      " [  23    3    5   22    6   18    9    0  882    6]\n",
      " [   8    3    4   15   57    9    0   22   14  877]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.23178459703922272,\n",
       " 'eval_f1': 0.9282962114422455,\n",
       " 'eval_precision': 0.9285663043775354,\n",
       " 'eval_recall': 0.9285,\n",
       " 'eval_accuracy': 0.9285,\n",
       " 'eval_runtime': 3.4166,\n",
       " 'eval_samples_per_second': 2926.901,\n",
       " 'eval_steps_per_second': 45.952,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/938], Loss: 2.1903\n",
      "Epoch [1/5], Step [200/938], Loss: 2.0577\n",
      "Epoch [1/5], Step [300/938], Loss: 1.9495\n",
      "Epoch [1/5], Step [400/938], Loss: 1.8025\n",
      "Epoch [1/5], Step [500/938], Loss: 1.6161\n",
      "Epoch [1/5], Step [600/938], Loss: 1.5318\n",
      "Epoch [1/5], Step [700/938], Loss: 1.4546\n",
      "Epoch [1/5], Step [800/938], Loss: 1.3805\n",
      "Epoch [1/5], Step [900/938], Loss: 1.2134\n",
      "Epoch [2/5], Step [100/938], Loss: 1.2599\n",
      "Epoch [2/5], Step [200/938], Loss: 1.0751\n",
      "Epoch [2/5], Step [300/938], Loss: 1.2669\n",
      "Epoch [2/5], Step [400/938], Loss: 1.0585\n",
      "Epoch [2/5], Step [500/938], Loss: 1.0870\n",
      "Epoch [2/5], Step [600/938], Loss: 0.9355\n",
      "Epoch [2/5], Step [700/938], Loss: 0.9594\n",
      "Epoch [2/5], Step [800/938], Loss: 0.9366\n",
      "Epoch [2/5], Step [900/938], Loss: 0.9701\n",
      "Epoch [3/5], Step [100/938], Loss: 0.9047\n",
      "Epoch [3/5], Step [200/938], Loss: 0.7651\n",
      "Epoch [3/5], Step [300/938], Loss: 0.8008\n",
      "Epoch [3/5], Step [400/938], Loss: 0.7867\n",
      "Epoch [3/5], Step [500/938], Loss: 0.8615\n",
      "Epoch [3/5], Step [600/938], Loss: 0.8128\n",
      "Epoch [3/5], Step [700/938], Loss: 0.8304\n",
      "Epoch [3/5], Step [800/938], Loss: 0.6121\n",
      "Epoch [3/5], Step [900/938], Loss: 0.7149\n",
      "Epoch [4/5], Step [100/938], Loss: 0.7157\n",
      "Epoch [4/5], Step [200/938], Loss: 0.5799\n",
      "Epoch [4/5], Step [300/938], Loss: 0.7208\n",
      "Epoch [4/5], Step [400/938], Loss: 0.6021\n",
      "Epoch [4/5], Step [500/938], Loss: 0.5478\n",
      "Epoch [4/5], Step [600/938], Loss: 0.6199\n",
      "Epoch [4/5], Step [700/938], Loss: 0.6494\n",
      "Epoch [4/5], Step [800/938], Loss: 0.6407\n",
      "Epoch [4/5], Step [900/938], Loss: 0.6244\n",
      "Epoch [5/5], Step [100/938], Loss: 0.5586\n",
      "Epoch [5/5], Step [200/938], Loss: 0.4825\n",
      "Epoch [5/5], Step [300/938], Loss: 0.4559\n",
      "Epoch [5/5], Step [400/938], Loss: 0.7134\n",
      "Epoch [5/5], Step [500/938], Loss: 0.4097\n",
      "Epoch [5/5], Step [600/938], Loss: 0.4796\n",
      "Epoch [5/5], Step [700/938], Loss: 0.4521\n",
      "Epoch [5/5], Step [800/938], Loss: 0.5151\n",
      "Epoch [5/5], Step [900/938], Loss: 0.4971\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m---> 58\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m     _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     60\u001b[0m     total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 25\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 25\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog_softmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(x), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Logan\\Desktop\\Research\\MOE-BitNet158\\bitlinear.py:47\u001b[0m, in \u001b[0;36mBitLinear.forward\u001b[1;34m(self, _input)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, _input: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m---> 47\u001b[0m     normalized_input: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     input_gamma: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m normalized_input\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     49\u001b[0m     weight_abs_mean: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:201\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:2546\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2544\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[0;32m   2545\u001b[0m     )\n\u001b[1;32m-> 2546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, datasets\n",
    "from bitlinear import BitLinear as Linear\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 784\n",
    "hidden_size = 100\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = Linear(input_size, hidden_size)\n",
    "        self.fc2 = Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Create the model and optimizer\n",
    "model = Net(input_size, hidden_size, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(images.view(-1, 28 * 28).to(device)).cpu()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=False)\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print training information\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 89.72%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images.view(-1, 28 * 28).to(device)).cpu()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
