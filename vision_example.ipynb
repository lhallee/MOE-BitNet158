{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from config import BitformerConfig\n",
    "from model_zoo import VisionBitformerForImageClassification, VisionBitformerForSemanticSegmentation\n",
    "from metrics import compute_metrics_single_label_classification\n",
    "from trainer import get_trainer\n",
    "from data_zoo import get_vision_dataset, vision_collator\n",
    "from utils import get_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_path = './yamls/vision/small.yaml'\n",
    "args = get_yaml(yaml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args['model_config']['bitnet'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.131476"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg = BitformerConfig(**args['model_config'], num_labels=args['general_config']['num_labels'])\n",
    "model = VisionBitformerForImageClassification(config=cfg)\n",
    "model.num_parameters() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'mnist'\n",
    "train_dataset, test_dataset = get_vision_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = get_trainer(model=model,\n",
    "                      train_dataset=train_dataset,\n",
    "                      valid_dataset=test_dataset,\n",
    "                      compute_metrics=compute_metrics_single_label_classification,\n",
    "                      data_collator=vision_collator,\n",
    "                      **args['training_args'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126b82650b774f9d90708cad49c12879",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0461, 'grad_norm': 6.677570343017578, 'learning_rate': 0.0004900072000534774, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18880aa10fc143b38face154546c91a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5116379261016846, 'eval_f1': 0.8410506357325556, 'eval_precision': 0.8495047742662352, 'eval_recall': 0.8411, 'eval_accuracy': 0.8411, 'eval_runtime': 2.1765, 'eval_samples_per_second': 4594.562, 'eval_steps_per_second': 72.135, 'epoch': 1.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:1961\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1961\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1964\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1967\u001b[0m ):\n\u001b[0;32m   1968\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:2911\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2909\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   2910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2911\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2913\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:1966\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   1964\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1965\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1966\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Logan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e0ad62d338e4eca8fadd8a89b4362ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9380 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8597, 'grad_norm': 1.9200587272644043, 'learning_rate': 0.0004900072000534774, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8728ff736b4b27bd7521a02b7bf530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3140251636505127, 'eval_f1': 0.9135553046837643, 'eval_precision': 0.9142339999560493, 'eval_recall': 0.9139, 'eval_accuracy': 0.9139, 'eval_runtime': 0.7525, 'eval_samples_per_second': 13288.821, 'eval_steps_per_second': 208.634, 'epoch': 1.0}\n",
      "{'loss': 0.2633, 'grad_norm': 1.5263727903366089, 'learning_rate': 0.00045615929491282483, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17dc15f586204cd5961951d103b09958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21613578498363495, 'eval_f1': 0.9358811972883226, 'eval_precision': 0.9367202103839279, 'eval_recall': 0.9359, 'eval_accuracy': 0.9359, 'eval_runtime': 0.7631, 'eval_samples_per_second': 13104.694, 'eval_steps_per_second': 205.744, 'epoch': 2.0}\n",
      "{'loss': 0.1922, 'grad_norm': 1.6930099725723267, 'learning_rate': 0.00040169749790445905, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7483a5bda37947c5a06f57e9befb3401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.17053326964378357, 'eval_f1': 0.9475878357234756, 'eval_precision': 0.9478322857344401, 'eval_recall': 0.9476, 'eval_accuracy': 0.9476, 'eval_runtime': 0.7619, 'eval_samples_per_second': 13125.625, 'eval_steps_per_second': 206.072, 'epoch': 3.0}\n",
      "{'loss': 0.1612, 'grad_norm': 0.7695346474647522, 'learning_rate': 0.0003320674504433184, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d774b545914e53b933fedaf228ea1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15335500240325928, 'eval_f1': 0.9524743689204, 'eval_precision': 0.95299495516058, 'eval_recall': 0.9525, 'eval_accuracy': 0.9525, 'eval_runtime': 0.7715, 'eval_samples_per_second': 12962.49, 'eval_steps_per_second': 203.511, 'epoch': 4.0}\n",
      "{'loss': 0.1419, 'grad_norm': 1.5058592557907104, 'learning_rate': 0.000254231469070671, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33c833e042c4c649d6cca839fb68c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1420908421278, 'eval_f1': 0.9574239546636701, 'eval_precision': 0.9578308720308931, 'eval_recall': 0.9574, 'eval_accuracy': 0.9574, 'eval_runtime': 0.7818, 'eval_samples_per_second': 12790.581, 'eval_steps_per_second': 200.812, 'epoch': 5.0}\n",
      "{'loss': 0.1283, 'grad_norm': 0.12763918936252594, 'learning_rate': 0.00017597238261366985, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f9b192afb54a82b51a6673f477a605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.129969522356987, 'eval_f1': 0.961242367614776, 'eval_precision': 0.9614252933581583, 'eval_recall': 0.9613, 'eval_accuracy': 0.9613, 'eval_runtime': 0.7893, 'eval_samples_per_second': 12669.037, 'eval_steps_per_second': 198.904, 'epoch': 6.0}\n",
      "{'loss': 0.1174, 'grad_norm': 2.4719347953796387, 'learning_rate': 0.00010511532622604558, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10ab3fa963e491ca459ae27869b0867",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12279283255338669, 'eval_f1': 0.9640682937797396, 'eval_precision': 0.9640990308197468, 'eval_recall': 0.9641, 'eval_accuracy': 0.9641, 'eval_runtime': 0.7619, 'eval_samples_per_second': 13125.05, 'eval_steps_per_second': 206.063, 'epoch': 7.0}\n",
      "{'loss': 0.1106, 'grad_norm': 1.9979044198989868, 'learning_rate': 4.8745305214285054e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487265d627ee4f38858d96d444a8b6dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.12025178223848343, 'eval_f1': 0.9634540007925865, 'eval_precision': 0.9635174928552249, 'eval_recall': 0.9635, 'eval_accuracy': 0.9635, 'eval_runtime': 0.7837, 'eval_samples_per_second': 12760.486, 'eval_steps_per_second': 200.34, 'epoch': 8.0}\n",
      "{'loss': 0.1056, 'grad_norm': 1.1408836841583252, 'learning_rate': 1.2498764533288465e-05, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a73c2e4a35542a49370a300df8cd4a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11933530122041702, 'eval_f1': 0.9643829509011197, 'eval_precision': 0.9644782761401038, 'eval_recall': 0.9644, 'eval_accuracy': 0.9644, 'eval_runtime': 0.7708, 'eval_samples_per_second': 12973.777, 'eval_steps_per_second': 203.688, 'epoch': 9.0}\n",
      "{'loss': 0.1031, 'grad_norm': 2.4104082584381104, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4163bef1824edfa28230197f481eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./results\\checkpoint-9380 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.11868536472320557, 'eval_f1': 0.9640774850942858, 'eval_precision': 0.9641373508731603, 'eval_recall': 0.9641, 'eval_accuracy': 0.9641, 'eval_runtime': 0.797, 'eval_samples_per_second': 12547.586, 'eval_steps_per_second': 196.997, 'epoch': 10.0}\n",
      "{'train_runtime': 112.5335, 'train_samples_per_second': 5331.745, 'train_steps_per_second': 83.353, 'train_loss': 0.2183222813392753, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9e40c6da504de29e86018195433347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.11933530122041702,\n",
       " 'eval_f1': 0.9643829509011197,\n",
       " 'eval_precision': 0.9644782761401038,\n",
       " 'eval_recall': 0.9644,\n",
       " 'eval_accuracy': 0.9644,\n",
       " 'eval_runtime': 0.7916,\n",
       " 'eval_samples_per_second': 12633.389,\n",
       " 'eval_steps_per_second': 198.344,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 24, 7, 7])\n",
      "torch.Size([64, 24, 14, 14])\n",
      "torch.Size([64, 24, 3, 3])\n",
      "torch.Size([64, 24, 12, 12])\n",
      "torch.Size([64, 24, 6, 6])\n",
      "torch.Size([64, 24, 12, 12])\n",
      "torch.Size([64, 24, 3, 3])\n",
      "torch.Size([64, 24, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.rand(64, 24, 14, 14)\n",
    "\n",
    "x = nn.AvgPool2d(2)(x)\n",
    "print(x.shape)\n",
    "x = nn.Upsample(scale_factor=2)(x)\n",
    "print(x.shape)\n",
    "x = nn.AvgPool2d(4)(x)\n",
    "print(x.shape)\n",
    "x = nn.Upsample(scale_factor=4)(x)\n",
    "print(x.shape)\n",
    "x = nn.MaxPool2d(2)(x)\n",
    "print(x.shape)\n",
    "x = nn.Upsample(scale_factor=2)(x)\n",
    "print(x.shape)\n",
    "x = nn.MaxPool2d(4)(x)\n",
    "print(x.shape)\n",
    "x = nn.Upsample(scale_factor=4)(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 24, 42, 14])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(64, 24, 14, 14)\n",
    "\n",
    "class HANCLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements Hierarchical Aggregation of Neighborhood Context operation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_chnl, out_chnl, k):\n",
    "        \"\"\"\n",
    "        Initialization\n",
    "\n",
    "        Args:\n",
    "            in_chnl (int): number of input channels\n",
    "            out_chnl (int): number of output channels\n",
    "            k (int): value of k in HANC\n",
    "        \"\"\"\n",
    "\n",
    "        super(HANCLayer, self).__init__()\n",
    "\n",
    "        self.k = k\n",
    "\n",
    "        self.cnv = nn.Conv2d((2 * k - 1) * in_chnl, out_chnl, kernel_size=(1, 1))\n",
    "        self.act = nn.LeakyReLU()\n",
    "        self.bn = nn.BatchNorm2d(out_chnl)\n",
    "\n",
    "\n",
    "    def forward(self, inp):\n",
    "        batch_size, num_channels, H, W = inp.size()\n",
    "        x = inp\n",
    "\n",
    "        if self.k == 1:\n",
    "            x = inp\n",
    "\n",
    "        elif self.k == 2:\n",
    "            H_2 = H // 2\n",
    "            W_2 = W // 2\n",
    "            x = torch.concat(\n",
    "                [\n",
    "                    x,\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveAvgPool2d((H_2, W_2))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveMaxPool2d((H_2, W_2))(x)),\n",
    "                ],\n",
    "                dim=2,\n",
    "            )\n",
    "\n",
    "        elif self.k == 3:\n",
    "            H_2 = H // 2\n",
    "            W_2 = W // 2\n",
    "            H_4 = H // 4\n",
    "            W_4 = W // 4\n",
    "            x = torch.concat(\n",
    "                [\n",
    "                    x,\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveAvgPool2d((H_2, W_2))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveAvgPool2d((H_4, W_4))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveMaxPool2d((H_2, W_2))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveMaxPool2d((H_4, W_4))(x)),\n",
    "                ],\n",
    "                dim=2,\n",
    "            )\n",
    "\n",
    "        elif self.k == 4:\n",
    "            H_2 = H // 2\n",
    "            W_2 = W // 2\n",
    "            H_4 = H // 4\n",
    "            W_4 = W // 4\n",
    "            H_8 = H // 8\n",
    "            W_8 = W // 8\n",
    "            x = torch.concat(\n",
    "                [\n",
    "                    x,\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveAvgPool2d((H_2, W_2))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveAvgPool2d((H_4, W_4))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveAvgPool2d((H_8, W_8))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveMaxPool2d((H_2, W_2))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveMaxPool2d((H_4, W_4))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveMaxPool2d((H_8, W_8))(x)),\n",
    "                ],\n",
    "                dim=2,\n",
    "            )\n",
    "\n",
    "        elif self.k == 5:\n",
    "            H_2 = H // 2\n",
    "            W_2 = W // 2\n",
    "            H_4 = H // 4\n",
    "            W_4 = W // 4\n",
    "            H_8 = H // 8\n",
    "            W_8 = W // 8\n",
    "            H_16 = H // 16\n",
    "            W_16 = W // 16\n",
    "            x = torch.concat(\n",
    "                [\n",
    "                    x,\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveAvgPool2d((H_2, W_2))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveAvgPool2d((H_4, W_4))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveAvgPool2d((H_8, W_8))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveAvgPool2d((H_16, W_16))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveMaxPool2d((H_2, W_2))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveMaxPool2d((H_4, W_4))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveMaxPool2d((H_8, W_8))(x)),\n",
    "                    nn.Upsample(size=(H, W))(nn.AdaptiveMaxPool2d((H_16, W_16))(x)),\n",
    "                ],\n",
    "                dim=2,\n",
    "            )\n",
    "\n",
    "        x = x.view(batch_size, num_channels * (2 * self.k - 1), H, W)\n",
    "        x = self.act(self.bn(self.cnv(x)))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
